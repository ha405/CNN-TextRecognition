{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10380090,"sourceType":"datasetVersion","datasetId":6430095}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Imports</h1>","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import datasets, transforms\nfrom tqdm import tqdm \nfrom collections import defaultdict\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:03:39.897905Z","iopub.execute_input":"2025-01-06T03:03:39.898326Z","iopub.status.idle":"2025-01-06T03:03:43.202153Z","shell.execute_reply.started":"2025-01-06T03:03:39.898293Z","shell.execute_reply":"2025-01-06T03:03:43.200927Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"<h1> Dataloader </h1>","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataset_folder, labels_file, transform=None):\n        self.dataset_folder = dataset_folder\n        self.labels_file = labels_file\n        self.transform = transform\n        self.data = []\n        self.labels = []\n        self.label_dict = {}\n        self.label_to_idx = {}\n        \n        with open(labels_file, 'r', encoding='utf-8') as f:\n            for line in f:\n                img_path, label = line.strip().split('\\t')\n                img_name = img_path.split('/')[-1]  \n                self.data.append(img_name)\n                self.labels.append(label)\n                \n                if label not in self.label_dict:\n                    self.label_dict[label] = len(self.label_dict)\n                    self.label_to_idx[len(self.label_dict) - 1] = label\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = self.data[idx]\n        label = self.labels[idx]\n        img_path = os.path.join(self.dataset_folder, img_name)\n        image = Image.open(img_path).convert(\"L\")\n        label_encoded = self.label_dict[label]\n        if self.transform:\n            image = self.transform(image)\n        return image, label_encoded\n\ntransform = transforms.Compose([\n    transforms.Resize((28, 28)),\n    transforms.Grayscale(num_output_channels=1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\ndataset_folder = r'/kaggle/input/urdulig/Dataset'\nlabels_file = r'/kaggle/input/urdulig/Dataset/Labels.txt'\ndataset = CustomDataset(dataset_folder, labels_file, transform=transform)\n\ntrain_data, val_data = train_test_split(list(zip(dataset.data, dataset.labels)), test_size=0.2, random_state=42)\n\ntrain_dataset = CustomDataset(dataset_folder, labels_file, transform=transform)\ntrain_dataset.data, train_dataset.labels = zip(*train_data)\n\nval_dataset = CustomDataset(dataset_folder, labels_file, transform=transform)\nval_dataset.data, val_dataset.labels = zip(*val_data)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\nnum_classes = len(dataset.label_dict)\n\nprint(f\"Train dataset size: {len(train_loader.dataset)}\")\nprint(f\"Validation dataset size: {len(val_loader.dataset)}\")\nprint(f\"Number of classes: {num_classes}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:03:44.551877Z","iopub.execute_input":"2025-01-06T03:03:44.552438Z","iopub.status.idle":"2025-01-06T03:03:44.795767Z","shell.execute_reply.started":"2025-01-06T03:03:44.552403Z","shell.execute_reply":"2025-01-06T03:03:44.794640Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 30936\nValidation dataset size: 7734\nNumber of classes: 3867\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"<h1> Architecture </h1>\nCNN-Fully Connected Layers","metadata":{}},{"cell_type":"code","source":"class CRNNForOCR(nn.Module):\n    def __init__(self, num_classes, dropout=0.3):\n        super(CRNNForOCR, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n        )\n        self.conv1x1 = nn.Conv2d(128, 256, kernel_size=1)\n        self.lstm = nn.LSTM(input_size=768, hidden_size=256, num_layers=3, batch_first=True, bidirectional=True, dropout=dropout)\n        self.fc = nn.Linear(256 * 2, num_classes)\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.conv1x1(x)\n        batch_size, channels, height, width = x.size()\n        x = x.permute(0, 3, 1, 2).contiguous()\n        x = x.view(batch_size, width, channels * height)\n        x, _ = self.lstm(x)\n        x = x[:, -1, :]\n        x = self.fc(x)\n        return x\n\ninput_height = 28\nmodel = CRNNForOCR(num_classes=len(dataset.label_dict), dropout=0.5)\n\n# Training Configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\nnum_epochs = 50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:11:04.829331Z","iopub.execute_input":"2025-01-06T03:11:04.829709Z","iopub.status.idle":"2025-01-06T03:11:04.903688Z","shell.execute_reply.started":"2025-01-06T03:11:04.829677Z","shell.execute_reply":"2025-01-06T03:11:04.902458Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"<h1> Training </h1>","metadata":{}},{"cell_type":"code","source":"for epoch in range(1, num_epochs + 1):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        _, predicted = torch.max(outputs, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    avg_train_loss = running_loss / len(train_loader)\n    train_accuracy = 100 * correct_train / total_train\n\n    print(f\"Epoch {epoch}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n\n    if epoch % 5 == 0:\n        model.eval()\n        correct_val = 0\n        total_val = 0\n        val_loss = 0.0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images = images.to(device)\n                labels = labels.to(device)\n\n                outputs = model(images)\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                total_val += labels.size(0)\n                correct_val += (predicted == labels).sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        val_accuracy = 100 * correct_val / total_val\n\n        print(f\"Epoch {epoch}/{num_epochs}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T03:11:08.857891Z","iopub.execute_input":"2025-01-06T03:11:08.858442Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50, Train Loss: 8.2629, Train Accuracy: 0.04%\nEpoch 2/50, Train Loss: 7.3954, Train Accuracy: 0.33%\nEpoch 3/50, Train Loss: 5.4680, Train Accuracy: 3.12%\nEpoch 4/50, Train Loss: 3.9847, Train Accuracy: 11.06%\nEpoch 5/50, Train Loss: 3.0253, Train Accuracy: 22.49%\nEpoch 5/50, Val Loss: 2.6868, Val Accuracy: 28.92%\n","output_type":"stream"}],"execution_count":null}]}